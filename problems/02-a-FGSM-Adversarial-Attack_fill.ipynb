{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fast Gradient Sign Method (FGSM) Adversarial Attack Workshop\n",
    "\n",
    "## Introduction to Adversarial Attacks\n",
    "In this workshop, we'll explore how to create adversarial examples using the Fast Gradient Sign Method (FGSM). These examples are carefully crafted perturbations that can cause a deep learning model to misclassify images, despite the changes being nearly imperceptible to human eyes.\n",
    "\n",
    "## Setup and Dependencies"
   ],
   "id": "3d118b903e62e7c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Install and Import Dependencies\n",
    "Run this cell to install and import all required libraries"
   ],
   "id": "21040ea175aca36e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Pre-trained Model",
   "id": "787b5913a4cf9c02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load Pre-trained ResNet50 Model\n",
    "# This cell loads a pre-trained ResNet50 model that we'll try to fool\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "print(\"Model loaded successfully!\")"
   ],
   "id": "cbfe455f2002e04c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Helper functions",
   "id": "bcb930881fb03f9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Image Preprocessing Function\n",
    "# This function prepares images for our model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses an image for ResNet50.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Preprocessed image array\n",
    "    \"\"\"\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = preprocess_input(image)\n",
    "    return image"
   ],
   "id": "bf53447403723eaf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## FGSM Attack Implementation",
   "id": "124da221fe10b66d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# This cell contains the core FGSM attack implementation\n",
    "\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    \"\"\"\n",
    "    Implements the Fast Gradient Sign Method attack.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image\n",
    "        epsilon: Attack strength parameter\n",
    "        data_grad: Gradient of the loss with respect to the input image\n",
    "        \n",
    "    Returns:\n",
    "        Adversarial image\n",
    "    \"\"\"\n",
    "    sign_data_grad = tf.sign(data_grad)\n",
    "    perturbed_image = image + epsilon * sign_data_grad\n",
    "    perturbed_image = tf.clip_by_value(perturbed_image, -1, 1)\n",
    "    return perturbed_image\n",
    "\n",
    "def generate_adversarial_example(image, epsilon):\n",
    "    \"\"\"\n",
    "    Generates an adversarial example using FGSM.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image\n",
    "        epsilon: Attack strength parameter\n",
    "        \n",
    "    Returns:\n",
    "        Adversarial version of the input image\n",
    "    \"\"\"\n",
    "    image_tensor = tf.convert_to_tensor(image)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image_tensor)\n",
    "        prediction = model(image_tensor)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(prediction, prediction)\n",
    "    \n",
    "    gradient = tape.gradient(loss, image_tensor)\n",
    "    perturbed_image = fgsm_attack(image_tensor, epsilon, gradient)\n",
    "    return perturbed_image"
   ],
   "id": "c1c348949d0bffdc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generate and Test Adversarial Example",
   "id": "656d6b360aa73df9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Run this cell to create and test an adversarial example\n",
    "# You can modify the epsilon value to control attack strength\n",
    "\n",
    "image_path = \"./data/pizza_2.jpg\"  # @param {type:\"string\"}\n",
    "epsilon = 0.01  # @param {type:\"slider\", min:0.001, max:0.1, step:0.001}\n",
    "\n",
    "# Load and preprocess the image\n",
    "original_image = preprocess_image(image_path)\n",
    "\n",
    "# Generate adversarial example\n",
    "adversarial_image = generate_adversarial_example(original_image, epsilon)\n",
    "\n",
    "# Make predictions\n",
    "original_pred = model.predict(original_image)\n",
    "adversarial_pred = model.predict(adversarial_image)\n",
    "\n",
    "# Decode predictions\n",
    "original_label = decode_predictions(original_pred)[0][0]\n",
    "adversarial_label = decode_predictions(adversarial_pred)[0][0]"
   ],
   "id": "4e7b382530f2bf04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualize Results",
   "id": "ed9efa4441f24a70"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualize Original vs Adversarial Images\n",
    "# This cell will display the original and adversarial images side by side\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(tf.keras.preprocessing.image.array_to_img(original_image[0]))\n",
    "plt.title(f\"Original: {original_label[1]}\\nConfidence: {original_label[2]:.2f}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(tf.keras.preprocessing.image.array_to_img(adversarial_image[0].numpy()))\n",
    "plt.title(f\"Adversarial: {adversarial_label[1]}\\nConfidence: {adversarial_label[2]:.2f}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Original prediction: {original_label[1]} ({original_label[2]:.2f})\")\n",
    "print(f\"Adversarial prediction: {adversarial_label[1]} ({adversarial_label[2]:.2f})\")"
   ],
   "id": "f9069837d162ca04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c26aa29e2fd0c72e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Extra Exercise Section\n",
    "Try experimenting with:\n",
    "1. Different epsilon values - how does this affect the attack's success and visibility?\n",
    "2. Different input images - do some types of images work better than others?\n",
    "3. Different target classes - can you modify the attack to target a specific class?"
   ],
   "id": "a5e513acad49e986"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Additional Notes:\n",
    "- The epsilon value controls the strength of the attack. Larger values create stronger attacks but more visible perturbations.\n",
    "- Some images may be more resistant to adversarial attacks than others.\n",
    "- The success of the attack can vary depending on the confidence of the original prediction."
   ],
   "id": "9e2c31c68a04b3a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
