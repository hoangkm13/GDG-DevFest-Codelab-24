{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/linhkid/GDG-DevFest-Codelab-24/blob/main/problems/02-a-FGSM-Adversarial-Attack_fill.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d118b903e62e7c1",
   "metadata": {
    "id": "3d118b903e62e7c1"
   },
   "source": [
    "# Fast Gradient Sign Method (FGSM) Adversarial Attack Workshop\n",
    "\n",
    "## Introduction to Adversarial Attacks\n",
    "In this workshop, we'll explore how to create adversarial examples using the Fast Gradient Sign Method (FGSM). These examples are carefully crafted perturbations that can cause a deep learning model to misclassify images, despite the changes being nearly imperceptible to human eyes.\n",
    "\n",
    "## Learning objectives\n",
    "After completing this workshop, you'll be able to:\n",
    "\n",
    "- Create adversarial examples using the Fast Gradient Sign Method (FGSM)\n",
    "- Understand the concepts behind adversarial attacks\n",
    "- Implement the FGSM attack\n",
    "\n",
    "## Approach\n",
    "\n",
    "- Utilizing a pre-trained Resnet50 model, we input a pizza image to calculate the loss value. From this loss value, the gradient of the loss function is computed.\n",
    "- Next, we take the sign of the gradient and multiply it by epsilon to generate a perturbation.\n",
    "- This perturbation is added to the original image to create an adversarial image.\n",
    "- Finally, the adversarial image is fed back into Resnet50, and the prediction results are observed to evaluate the effectiveness of the attack.\n",
    "\n",
    "\n",
    "## Key Terms\n",
    "\n",
    "- Fast Gradient Sign Method (FGSM): A method for creating adversarial examples by perturbing the input image in the direction of the gradient of the loss function with respect to the input image.\n",
    "- Adversarial attacks: A technique for creating adversarial examples that can be used to fool machine learning models\n",
    "\n",
    "## Application\n",
    "Detecting vulnerabilities and misjudgments in systems:\n",
    "\n",
    "- Facial recognition\n",
    "- Sign recognition\n",
    "- Self-driving cars\n",
    "- etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21040ea175aca36e",
   "metadata": {
    "id": "21040ea175aca36e"
   },
   "source": [
    "### Install and Import Dependencies\n",
    "Run this cell to install and import all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "id": "initial_id"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787b5913a4cf9c02",
   "metadata": {
    "id": "787b5913a4cf9c02"
   },
   "source": [
    "### Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe455f2002e04c",
   "metadata": {
    "id": "cbfe455f2002e04c"
   },
   "outputs": [],
   "source": [
    "# Load Pre-trained ResNet50 Model\n",
    "# This cell loads a pre-trained ResNet50 model that we'll try to fool\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb930881fb03f9e",
   "metadata": {
    "id": "bcb930881fb03f9e"
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf53447403723eaf",
   "metadata": {
    "id": "bf53447403723eaf"
   },
   "outputs": [],
   "source": [
    "# Image Preprocessing Function\n",
    "# This function prepares images for our model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses an image for ResNet50.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Preprocessed image array\n",
    "    \"\"\"\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = preprocess_input(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124da221fe10b66d",
   "metadata": {
    "id": "124da221fe10b66d"
   },
   "source": [
    "## FGSM Attack Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c348949d0bffdc",
   "metadata": {
    "id": "c1c348949d0bffdc"
   },
   "outputs": [],
   "source": [
    "# This cell contains the core FGSM attack implementation\n",
    "\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    \"\"\"\n",
    "    Implements the Fast Gradient Sign Method attack.\n",
    "\n",
    "    Args:\n",
    "        image: Input image\n",
    "        epsilon: Attack strength parameter\n",
    "        data_grad: Gradient of the loss with respect to the input image\n",
    "\n",
    "    Returns:\n",
    "        Adversarial image\n",
    "    \"\"\"\n",
    "    sign_data_grad = tf.sign(data_grad)\n",
    "    # TODO: Fill in the appropriate code\n",
    "    perturbed_image = \"\"\"TODO: caculate the perturbed image value with epsilon and sign_data_grad\"\"\"\n",
    "    perturbed_image = tf.clip_by_value(perturbed_image, -1, 1)\n",
    "    return perturbed_image\n",
    "\n",
    "def generate_adversarial_example(image, epsilon):\n",
    "    \"\"\"\n",
    "    Generates an adversarial example using FGSM.\n",
    "\n",
    "    Args:\n",
    "        image: Input image\n",
    "        epsilon: Attack strength parameter\n",
    "\n",
    "    Returns:\n",
    "        Adversarial version of the input image\n",
    "    \"\"\"\n",
    "    # TODO: Fill in the appropriate code\n",
    "    image_tensor = tf.convert_to_tensor(\"\"\"TODO: generate the image tensor from Pizza image\"\"\")\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image_tensor)\n",
    "        # TODO: Fill in the appropriate code\n",
    "        prediction = \"\"\"TODO: generate the prediction from Pizza image\"\"\"\n",
    "        loss = tf.keras.losses.categorical_crossentropy(prediction, prediction)\n",
    "\n",
    "    gradient = tape.gradient(loss, image_tensor)\n",
    "    # TODO: Fill in the appropriate code\n",
    "    perturbed_image = \"\"\"TODO: generate the adversarial image with epsilon and gradient\"\"\"\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656d6b360aa73df9",
   "metadata": {
    "id": "656d6b360aa73df9"
   },
   "source": [
    "## Generate and Test Adversarial Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b382530f2bf04",
   "metadata": {
    "id": "4e7b382530f2bf04"
   },
   "outputs": [],
   "source": [
    "# Run this cell to create and test an adversarial example\n",
    "# You can modify the epsilon value to control attack strength\n",
    "# Download Pizza image from: https://github.com/linhkid/GDG-DevFest-Codelab-24/blob/main/data/pizza_2.jpg \n",
    "# Upload it to Files tab on Colab. Right click on it and select \"copy path\" \n",
    "\n",
    "# TODO: Fill in the appropriate code\n",
    "image_path = \"\"\"TODO: Fill in the appropriate code\"\"\"  # @param {type:\"string\"}\n",
    "epsilon = 0.089  # @param {type:\"slider\", min:0.001, max:0.1, step:0.001}\n",
    "\n",
    "# Load and preprocess the image\n",
    "# TODO: Fill in the appropriate code\n",
    "original_image = preprocess_image(\"\"\"TODO: Fill in the appropriate code\"\"\")\n",
    "\n",
    "# Generate adversarial example\n",
    "# TODO: Fill in the appropriate code\n",
    "adversarial_image = \"\"\"TODO: Fill in the appropriate code\"\"\"\n",
    "\n",
    "# Make predictions\n",
    "# TODO: Fill in the appropriate code\n",
    "original_pred = \"\"\"TODO: generate the prediction from Original Pizza image\"\"\"\n",
    "adversarial_pred = \"\"\"TODO: generate the prediction from Perturbed Pizza image\"\"\"\n",
    "\n",
    "# Decode predictions\n",
    "original_label = decode_predictions(original_pred)[0][0]\n",
    "# TODO: Fill in the appropriate code\n",
    "adversarial_label = \"\"\"TODO: generate the prediction label from Perturbed Pizza image\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9efa4441f24a70",
   "metadata": {
    "id": "ed9efa4441f24a70"
   },
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9069837d162ca04",
   "metadata": {
    "id": "f9069837d162ca04"
   },
   "outputs": [],
   "source": [
    "# Visualize Original vs Adversarial Images\n",
    "# This cell will display the original and adversarial images side by side\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(tf.keras.preprocessing.image.array_to_img(original_image[0]))\n",
    "plt.title(f\"Original: {original_label[1]}\\nConfidence: {original_label[2]:.2f}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(tf.keras.preprocessing.image.array_to_img(adversarial_image[0].numpy()))\n",
    "plt.title(f\"Adversarial: {adversarial_label[1]}\\nConfidence: {adversarial_label[2]:.2f}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Original prediction: {original_label[1]} ({original_label[2]:.2f})\")\n",
    "print(f\"Adversarial prediction: {adversarial_label[1]} ({adversarial_label[2]:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e513acad49e986",
   "metadata": {
    "id": "a5e513acad49e986"
   },
   "source": [
    "## Discussion\n",
    "- Why use the sign of the gradient instead of the value?\n",
    "- What information does the gradient of the loss function tell about the model?\n",
    "- What systems can FGSM be used to attack?\n",
    "- What are the applications of FGSM in practice?\n",
    "- How to build adversarial defenses from adversarial attacks?\n",
    "- FGSM focuses on changing the pixel values ​​of images. Can FGSM be applied to other types of data such as text and audio?\n",
    "- FGSM is a \"white-box\" attack method, which requires detailed information about the model. So how can we perform a \"black-box\" attack when we do not know the model?\n",
    "\n",
    "## Extra Exercise Section\n",
    "Try experimenting with:\n",
    "1. Different epsilon values - how does this affect the attack's success and visibility?\n",
    "2. Different input images - do some types of images work better than others?\n",
    "3. Different target classes - can you modify the attack to target a specific class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2c31c68a04b3a0",
   "metadata": {
    "id": "9e2c31c68a04b3a0"
   },
   "source": [
    "## Additional Notes:\n",
    "- The epsilon value controls the strength of the attack. Larger values create stronger attacks but more visible perturbations.\n",
    "- Some images may be more resistant to adversarial attacks than others.\n",
    "- The success of the attack can vary depending on the confidence of the original prediction."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
