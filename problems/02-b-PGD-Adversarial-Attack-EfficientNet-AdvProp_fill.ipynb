{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Adversarial Attacks on Deep Learning Models: EfficientNet and AdvProp",
   "id": "32cc7c16b6f624e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "In this workshop, we'll explore how to create adversarial examples that can fool deep learning models. We'll use EfficientNet and its Adversarial Propagation (AdvProp) variant as our target models, implementing a targeted Projected Gradient Descent (PGD) attack. This demonstrates both the vulnerabilities of deep learning models and techniques to make them more robust."
   ],
   "id": "a842decdcdaa9a61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Learning Objectives\n",
    "- Understand adversarial attacks and their implications for AI safety\n",
    "- Implement targeted PGD attacks on image classification models\n",
    "- Compare robustness between standard models and those trained with adversarial examples\n",
    "- Learn about transfer learning and model fine-tuning"
   ],
   "id": "24381a206d979240"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prerequisites\n",
    "- Basic understanding of deep learning and computer vision\n",
    "- Familiarity with TensorFlow and Keras\n",
    "- GPU-enabled environment (recommended)\n",
    "- Python 3.6 or later"
   ],
   "id": "8994ddc81987e7bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Initial Setup\n",
    "\n",
    "First, we'll set up our environment with the necessary dependencies:"
   ],
   "id": "b206174726173e14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Install required packages\n",
    "!pip install tensorflow-gpu==2.8.0\n",
    "!pip install tensorflow-datasets\n",
    "\n",
    "# Import necessary libraries\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 666\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ],
   "id": "b20a7b818145086a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 2. Dataset Preparation\n",
    "\n",
    "We'll use the TensorFlow Flowers dataset, which provides a good balance between simplicity and real-world applicability:"
   ],
   "id": "4aeefee956c897ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the Flowers dataset\n",
    "train_ds, validation_ds = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:85%]\", \"train[85%:]\"],\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "# Define class labels\n",
    "CLASSES = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n",
    "\n",
    "# Image preprocessing function\n",
    "SIZE = (224, 224)\n",
    "\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, SIZE)\n",
    "    return (image, label)\n",
    "\n",
    "# Prepare datasets with batching and prefetching\n",
    "BATCH_SIZE = 64\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = (\n",
    "    train_ds\n",
    "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
    "    .cache()\n",
    "    .shuffle(1024)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "validation_ds = (\n",
    "    validation_ds\n",
    "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
    "    .cache()\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")"
   ],
   "id": "dd000d93499e6ba5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 3. Model Architecture and Training\n",
    "\n",
    "We'll create two variants of EfficientNet: one with standard ImageNet weights and another with AdvProp weights:"
   ],
   "id": "8f0d1a7c393a4551"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_training_model(base_model):\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(5, activation=\"softmax\")(x)\n",
    "    return Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# Custom learning rate schedule\n",
    "def lrfn(epoch):\n",
    "    LR_START = 1e-5\n",
    "    LR_MAX = 1e-2\n",
    "    LR_RAMPUP_EPOCHS = 5\n",
    "    LR_SUSTAIN_EPOCHS = 0\n",
    "    LR_STEP_DECAY = 0.75\n",
    "    \n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//10)\n",
    "    return lr"
   ],
   "id": "ac8c5401ac2fae44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Adversarial Attack Implementation\n",
    "\n",
    "Here we implement our targeted PGD attack:"
   ],
   "id": "640b9429ac52922f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "EPS = 2./255\n",
    "\n",
    "def clip_eps(delta_tensor):\n",
    "    return tf.clip_by_value(delta_tensor, clip_value_min=-EPS, clip_value_max=EPS)\n",
    "\n",
    "def generate_adversaries_targeted(model, image_tensor, delta, true_index, target_index):\n",
    "    scc_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-3)\n",
    "\n",
    "    for t in range(350):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(delta)\n",
    "            inp = (image_tensor + delta)\n",
    "            predictions = model(inp, training=False)\n",
    "            loss = (- scc_loss(tf.convert_to_tensor([true_index]), predictions) + \n",
    "                    scc_loss(tf.convert_to_tensor([target_index]), predictions))\n",
    "            \n",
    "            if t % 20 == 0:\n",
    "                print(f\"Step {t}, Loss: {loss.numpy():.4f}\")\n",
    "                plt.imshow(50*delta.numpy().squeeze()+0.5)\n",
    "                plt.show()\n",
    "            \n",
    "        gradients = tape.gradient(loss, delta)\n",
    "        optimizer.apply_gradients([(gradients, delta)])\n",
    "        delta.assign_add(clip_eps(delta))\n",
    "\n",
    "    return delta\n",
    "\n",
    "def perturb_image(model, image, true, target):\n",
    "    print(\"Before adversarial attack\")\n",
    "    probabilities = model.predict(image)\n",
    "    class_index = np.argmax(probabilities)\n",
    "    print(f\"Ground-truth label: {CLASSES[true]} predicted label: {CLASSES[class_index]}\")\n",
    "    \n",
    "    image_tensor = tf.constant(image, dtype=tf.float32)\n",
    "    delta = tf.Variable(tf.zeros_like(image_tensor), trainable=True)\n",
    "    delta_tensor = generate_adversaries_targeted(model, image_tensor, delta, true, target)\n",
    "    \n",
    "    perturbed_image = (image_tensor + delta_tensor)\n",
    "    print(\"\\nAfter adversarial attack\")\n",
    "    preds = model.predict(perturbed_image)[0]\n",
    "    pred_label = CLASSES[np.argmax(preds)]\n",
    "    print(f\"Predicted label: {pred_label}\")\n",
    "    \n",
    "    return perturbed_image, delta_tensor"
   ],
   "id": "4ce0b965abdd808"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Running the Attack\n",
    "\n",
    "Now we can run our attack and visualize the results:"
   ],
   "id": "684996b3d1438f65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Select a sample image\n",
    "index = 15  # Example index\n",
    "sample_val_image = np.expand_dims(batch_images[index], 0)\n",
    "\n",
    "# Run attack on standard EfficientNet\n",
    "print(\"Attack on Standard EfficientNet:\")\n",
    "perturbed_standard, delta_standard = perturb_image(\n",
    "    model_eb0, \n",
    "    sample_val_image, \n",
    "    batch_labels[index].numpy(), \n",
    "    4  # Target class (tulips)\n",
    ")\n",
    "\n",
    "# Run attack on AdvProp EfficientNet\n",
    "print(\"\\nAttack on AdvProp EfficientNet:\")\n",
    "perturbed_advprop, delta_advprop = perturb_image(\n",
    "    model_eb0_ap, \n",
    "    sample_val_image, \n",
    "    batch_labels[index].numpy(), \n",
    "    4  # Target class (tulips)\n",
    ")\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(sample_val_image[0].astype(\"uint8\"))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(perturbed_standard[0].numpy().astype(\"uint8\"))\n",
    "plt.title(\"Standard EfficientNet Attack\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(perturbed_advprop[0].numpy().astype(\"uint8\"))\n",
    "plt.title(\"AdvProp EfficientNet Attack\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "id": "79173a858b452e31"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5dddde9dc6cbc26c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Analysis and Discussion\n",
    "\n",
    "### Key Observations\n",
    "1. The adversarial perturbations are imperceptible to human eyes but can fool the model\n",
    "2. AdvProp training provides some robustness against adversarial attacks\n",
    "3. The attack success rate varies between the two models\n",
    "\n",
    "### Security Implications\n",
    "- Model vulnerabilities in real-world applications\n",
    "- Importance of adversarial training\n",
    "- Trade-offs between accuracy and robustness\n",
    "\n",
    "## Additional Resources\n",
    "1. [AdvProp Paper](https://arxiv.org/abs/1911.09665)\n",
    "2. [EfficientNet Paper](https://arxiv.org/abs/1905.11946)\n",
    "3. [PGD Attack Paper](https://arxiv.org/abs/1706.06083)\n",
    "\n",
    "## Exercises for Participants\n",
    "1. Try different epsilon values for the attack\n",
    "2. Experiment with different target classes\n",
    "3. Modify the attack algorithm parameters\n",
    "4. Compare results with different model architectures"
   ],
   "id": "ec17bf4d1ce9d284"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
