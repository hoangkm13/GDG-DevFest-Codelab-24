{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "<a href=\"https://colab.research.google.com/github/linhkid/GDG-DevFest-Codelab-24/blob/main/problems/02-b-PGD-Adversarial-Attack-EfficientNet-AdvProp_fill.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>",
   "id": "c5500b42cc0e8bc"
  },
  {
   "metadata": {
    "id": "32cc7c16b6f624e9"
   },
   "cell_type": "markdown",
   "source": [
    "# Adversarial Attacks on Deep Learning Models: EfficientNet and AdvProp"
   ],
   "id": "32cc7c16b6f624e9"
  },
  {
   "metadata": {
    "id": "a842decdcdaa9a61"
   },
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "In this workshop, we'll explore how to create adversarial examples that can fool deep learning models. We'll use EfficientNet and its Adversarial Propagation (AdvProp) variant as our target models, implementing a targeted Projected Gradient Descent (PGD) attack. This demonstrates both the vulnerabilities of deep learning models and techniques to make them more robust.\n",
    "\n",
    "### What are Adversarial Propagation and EfficientNet?\n",
    "\n",
    "- **Adversarial Propagation (AdvProp)**: A training method that improves adversarial robustness by propagating adversarial perturbations through the network during training. This helps the model learn to be robust against adversarial attacks.\n",
    "- **EfficientNet**: A family of convolutional neural networks that achieve state-of-the-art accuracy with fewer parameters and FLOPS. EfficientNet models are known for their scalability and performance across various tasks.\n",
    "- **Projected Gradient Descent (PGD)**: An iterative optimization technique used to generate adversarial examples. PGD attacks aim to maximize the model's loss by perturbing the input image within a specified epsilon range.\n",
    "\n",
    "![PGD](../img/pgd.png)"
   ],
   "id": "a842decdcdaa9a61"
  },
  {
   "metadata": {
    "id": "24381a206d979240"
   },
   "cell_type": "markdown",
   "source": [
    "### Learning Objectives\n",
    "- Understand adversarial attacks and their implications for AI safety\n",
    "- Implement targeted PGD attacks on image classification models\n",
    "- Compare robustness between standard models and those trained with adversarial examples\n",
    "- Learn about transfer learning and model fine-tuning"
   ],
   "id": "24381a206d979240"
  },
  {
   "metadata": {
    "id": "8994ddc81987e7bc"
   },
   "cell_type": "markdown",
   "source": [
    "### Prerequisites\n",
    "- Basic understanding of deep learning and computer vision\n",
    "- Familiarity with TensorFlow and Keras\n",
    "- GPU-enabled environment (recommended)\n",
    "- Python 3.6 or later"
   ],
   "id": "8994ddc81987e7bc"
  },
  {
   "metadata": {
    "id": "b206174726173e14"
   },
   "cell_type": "markdown",
   "source": [
    "## 1. Initial Setup\n",
    "\n",
    "First, we'll set up our environment with the necessary dependencies:"
   ],
   "id": "b206174726173e14"
  },
  {
   "metadata": {
    "id": "b20a7b818145086a",
    "outputId": "48c3682a-c449-45dd-c2d3-e57ab516b356",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "cell_type": "code",
   "source": [
    "# Install required packages\n",
    "!pip install protobuf==3.20.*\n",
    "!pip install tensorflow==2.8.0 tensorflow-gpu==2.8.0\n",
    "!pip install tensorflow-datasets\n",
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 666\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ],
   "id": "b20a7b818145086a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "4aeefee956c897ac"
   },
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 2. Dataset Preparation\n",
    "\n",
    "We'll use the TensorFlow Flowers dataset, which provides a good balance between simplicity and real-world applicability:"
   ],
   "id": "4aeefee956c897ac"
  },
  {
   "metadata": {
    "id": "dd000d93499e6ba5",
    "outputId": "cb9e2ff7-28a2-4677-808e-f48412f7701e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the Flowers dataset\n",
    "train_ds, validation_ds = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    # TODO: Fill in the appropriate code\n",
    "    split=[\"train[:85%]\", \"\"\"TODO: Fill in the appropriate code\"\"\"],\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "# Define class labels\n",
    "CLASSES = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n",
    "\n",
    "# Image preprocessing function\n",
    "SIZE = (224, 224)\n",
    "\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, SIZE)\n",
    "    return (image, label)\n",
    "\n",
    "# Prepare datasets with batching and prefetching\n",
    "# TODO: Fill in the appropriate code\n",
    "BATCH_SIZE = \"\"\"TODO: Fill in the appropriate code\"\"\"\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = (\n",
    "    train_ds\n",
    "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
    "    .cache()\n",
    "    .shuffle(1024)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# TODO: Fill in the appropriate code\n",
    "validation_ds = (\n",
    "\"\"\"TODO: Fill in the appropriate code\"\"\"\n",
    ")"
   ],
   "id": "dd000d93499e6ba5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "8f0d1a7c393a4551"
   },
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 3. Model Architecture and Training\n",
    "\n",
    "We'll create two variants of EfficientNet: one with standard ImageNet weights and another with AdvProp weights:"
   ],
   "id": "8f0d1a7c393a4551"
  },
  {
   "metadata": {
    "id": "ac8c5401ac2fae44"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 4,
   "source": [
    "# TODO: Fill in the appropriate code\n",
    "def get_training_model(base_model):\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(\"\"\"TODO: Fill in the appropriate code\"\"\")\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = \"\"\"TODO: Fill in the appropriate code\"\"\"\n",
    "    return Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# Custom learning rate schedule\n",
    "def lrfn(epoch):\n",
    "    LR_START = 1e-5\n",
    "    LR_MAX = 1e-2\n",
    "    LR_RAMPUP_EPOCHS = 5\n",
    "    LR_SUSTAIN_EPOCHS = 0\n",
    "    LR_STEP_DECAY = 0.75\n",
    "\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//10)\n",
    "    return lr"
   ],
   "id": "ac8c5401ac2fae44"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot the progress"
   ],
   "metadata": {
    "id": "zmnZP4viZgWp"
   },
   "id": "zmnZP4viZgWp"
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_progress(hist):\n",
    "    plt.plot(hist.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(hist.history[\"val_loss\"], label=\"validation_loss\")\n",
    "    plt.plot(hist.history[\"accuracy\"], label=\"training_accuracy\")\n",
    "    plt.plot(hist.history[\"val_accuracy\"], label=\"validation_accuracy\")\n",
    "    plt.title(\"Training Progress\")\n",
    "    plt.ylabel(\"accuracy/loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "XajgTiAsZrMJ"
   },
   "id": "XajgTiAsZrMJ",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fetch the [AdvProp](https://arxiv.org/abs/1911.09665) training checkpoints for EfficientNetB0 and convert the checkpoints to `.h5`."
   ],
   "metadata": {
    "id": "m6naWb3gbEXS"
   },
   "id": "m6naWb3gbEXS"
  },
  {
   "cell_type": "code",
   "source": [
    "!wget -q https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/advprop/efficientnet-b0.tar.gz\n",
    "!tar -xf efficientnet-b0.tar.gz"
   ],
   "metadata": {
    "id": "BY8QLMywawp6"
   },
   "id": "BY8QLMywawp6",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!wget -q https://raw.githubusercontent.com/yixingfu/tensorflow/updateweights/tensorflow/python/keras/applications/efficientnet_weight_update_util.py\n",
    "!python efficientnet_weight_update_util.py --model b0 --notop --ckpt \\\n",
    "       efficientnet-b0/model.ckpt --o efficientnetb0_notop.h5"
   ],
   "metadata": {
    "id": "uSGrLzEEawsy",
    "outputId": "7efcd0b9-5f3f-494b-b1f8-c72a5ce366a0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "uSGrLzEEawsy",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training an EfficientNetB0 initialized with adversarial propagation (AdvProp) weights"
   ],
   "metadata": {
    "id": "TS8HNZCSbVVe"
   },
   "id": "TS8HNZCSbVVe"
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the EfficientNetB0 model but exclude the classification layers\n",
    "# Note that the model was trained using AdvProp (https://arxiv.org/abs/1911.09665)\n",
    "base_model_eb0_ap = EfficientNetB0(weights=\"efficientnetb0_notop.h5\", include_top=False)\n",
    "base_model_eb0_ap.trainable = False # We are not fine-tuning at this point\n",
    "get_training_model(base_model_eb0_ap).summary()"
   ],
   "metadata": {
    "id": "C2CBXIlIawwl",
    "outputId": "ec46a3c2-7246-4032-cb01-ea97025279f7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "C2CBXIlIawwl",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lr2 = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n",
    "\n",
    "rng = [i for i in range(100)]\n",
    "y = [lrfn(x) for x in rng]\n",
    "plt.plot(rng, y);\n",
    "plt.xlabel('epoch',size=14); plt.ylabel('learning rate',size=14)\n",
    "plt.title('Training Schedule',size=16); plt.show()"
   ],
   "metadata": {
    "id": "WuUdW_HgawzN",
    "outputId": "c8bd4a24-1d0b-471f-84d0-048615fb3956",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    }
   },
   "id": "WuUdW_HgawzN",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Early stopping callback\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    ")"
   ],
   "metadata": {
    "id": "RHqzTIflaw12"
   },
   "id": "RHqzTIflaw12",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "# TODO: Fill in the appropriate code\n",
    "model_eb0_ap = get_training_model(\"\"\"TODO: Fill in the appropriate code\"\"\")\n",
    "model_eb0_ap.compile(\"\"\"TODO: Fill in the appropriate code\"\"\")\n",
    "start = time.time()\n",
    "h = model_eb0_ap.fit(\"\"\"TODO: Fill in the appropriate code\"\"\",\n",
    "                     callbacks=[lr2, es])\n",
    "print(\"Total training time (seconds): \",time.time()-start)\n",
    "plot_progress(h)"
   ],
   "metadata": {
    "id": "nv90Qndyaw4X",
    "outputId": "21d2c7f3-1a29-4868-ea99-7c6903002668",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "id": "nv90Qndyaw4X",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training an EfficientNetB0 initialized with ImageNet weights"
   ],
   "metadata": {
    "id": "Om2Y0LiibquU"
   },
   "id": "Om2Y0LiibquU"
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the EfficientNetB0 model but exclude the classification layers\n",
    "# This time the weights are from traditional ImageNet pre-training\n",
    "base_model_eb0 = EfficientNetB0(weights=\"imagenet\", include_top=False)\n",
    "base_model_eb0.trainable = False # We are not fine-tuning at this point"
   ],
   "metadata": {
    "id": "eyBvx28kbso6"
   },
   "id": "eyBvx28kbso6",
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "# TODO: Fill in the appropriate code\n",
    "model_eb0 = get_training_model(\"\"\"TODO: Fill in the appropriate code\"\"\")\n",
    "model_eb0.compile(\"\"\"TODO: Fill in the appropriate code\"\"\")\n",
    "start = time.time()\n",
    "h = model_eb0.fit(\"\"\"TODO: Fill in the appropriate code\"\"\",\n",
    "              callbacks=[lr2, es])\n",
    "print(\"Total training time (seconds): \",time.time()-start)\n",
    "plot_progress(h)"
   ],
   "metadata": {
    "id": "_n37Gf40btx2",
    "outputId": "34861e9e-7a36-485b-b486-17068593e73c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "id": "_n37Gf40btx2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plotting sample predictions"
   ],
   "metadata": {
    "id": "ta9oRsAMbwsA"
   },
   "id": "ta9oRsAMbwsA"
  },
  {
   "cell_type": "code",
   "source": [
    "# Utility to plot sample predictions\n",
    "def plot_predictions(images, labels, probability):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i, image in enumerate(images):\n",
    "        ax = plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "        predicted_label = CLASSES[np.argmax(probability[i])]\n",
    "        maximum_probability = \"{:.3f}\".format(max(probability[i]))\n",
    "        text = \"{} with probability: {}\".format(predicted_label, maximum_probability) + \\\n",
    "            \"\\nGround-truth: {}\".format(CLASSES[int(labels[i])])\n",
    "        plt.title(text)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "E8jEb1Fzbt0E"
   },
   "id": "E8jEb1Fzbt0E",
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference with the regular EfficienNet model"
   ],
   "metadata": {
    "id": "M5lsVfoMb59H"
   },
   "id": "M5lsVfoMb59H"
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's run inference on a batch of images from the validation set\n",
    "(batch_images, batch_labels) = next(iter(validation_ds))\n",
    "# TODO: Fill in the appropriate code\n",
    "predictions = \"\"\"TODO: Fill in the appropriate code\"\"\"\n",
    "plot_predictions(batch_images[:16], batch_labels[:16], predictions[:16])"
   ],
   "metadata": {
    "id": "LARl-lV6b6fC",
    "outputId": "fc9ca0bd-2cab-4be7-be96-50d6cc2434ea",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "id": "LARl-lV6b6fC",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference with the AdvProp weights initialized EfficientNet model"
   ],
   "metadata": {
    "id": "ZqpWOiG6b9A3"
   },
   "id": "ZqpWOiG6b9A3"
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's run inference on a batch of images from the validation set\n",
    "(batch_images, batch_labels) = next(iter(validation_ds))\n",
    "# TODO: Fill in the appropriate code\n",
    "predictions = \"\"\"TODO: Fill in the appropriate code\"\"\"\n",
    "plot_predictions(batch_images[:16], batch_labels[:16], predictions[:16])"
   ],
   "metadata": {
    "id": "JHDrF5Gob9ff",
    "outputId": "528fd9e8-e0cb-4a24-abbb-c8ed2bf83fcd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "id": "JHDrF5Gob9ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "640b9429ac52922f"
   },
   "cell_type": "markdown",
   "source": [
    "## 4. Adversarial Attack Implementation\n",
    "\n",
    "Here we implement our targeted PGD attack:"
   ],
   "id": "640b9429ac52922f"
  },
  {
   "metadata": {
    "id": "4ce0b965abdd808"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 20,
   "source": [
    "EPS = 2./255\n",
    "\n",
    "def clip_eps(delta_tensor):\n",
    "    return tf.clip_by_value(delta_tensor, clip_value_min=-EPS, clip_value_max=EPS)\n"
   ],
   "id": "4ce0b965abdd808"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this attack we will use PGD to simply maximize the loss for the given (true) class and at the same time minimize the loss for the target class such that the visual semantics of our input image does not get hampered."
   ],
   "metadata": {
    "id": "58ec6xR8cIlX"
   },
   "id": "58ec6xR8cIlX"
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_adversaries_targeted(model, image_tensor, delta, true_index, target_index):\n",
    "    scc_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-3)\n",
    "\n",
    "    for t in range(350):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(delta)\n",
    "            # TODO: Fill in the appropriate code\n",
    "            inp = (\"\"\"TODO: Fill in the appropriate code\"\"\")\n",
    "            predictions = model(\"\"\"TODO: Fill in the appropriate code\"\"\", training=False)\n",
    "            loss = (- scc_loss(tf.convert_to_tensor([true_index]), predictions) +\n",
    "                    scc_loss(tf.convert_to_tensor([target_index]), predictions))\n",
    "\n",
    "            if t % 20 == 0:\n",
    "                print(f\"Step {t}, Loss: {loss.numpy():.4f}\")\n",
    "                plt.imshow(50*delta.numpy().squeeze()+0.5)\n",
    "                plt.show()\n",
    "\n",
    "        gradients = tape.gradient(loss, delta)\n",
    "        optimizer.apply_gradients([(gradients, delta)])\n",
    "        delta.assign_add(clip_eps(delta))\n",
    "\n",
    "    return delta\n",
    "\n",
    "def perturb_image(model, image, true, target):\n",
    "    print(\"Before adversarial attack\")\n",
    "    # TODO: Fill in the appropriate code\n",
    "    probabilities = \"\"\"TODO: Fill in the appropriate code\"\"\"\n",
    "    class_index = np.argmax(\"\"\"TODO: Fill in the appropriate code\"\"\")\n",
    "    print(f\"Ground-truth label: {CLASSES[true]} predicted label: {CLASSES[class_index]}\")\n",
    "\n",
    "    image_tensor = tf.constant(image, dtype=tf.float32)\n",
    "    delta = tf.Variable(tf.zeros_like(image_tensor), trainable=True)\n",
    "    # TODO: Fill in the appropriate code\n",
    "    delta_tensor = \"\"\"TODO: Fill in the appropriate code\"\"\"\n",
    "\n",
    "    # TODO: Fill in the appropriate code\n",
    "    perturbed_image = (image_tensor + delta_tensor)\n",
    "    print(\"\\nAfter adversarial attack\")\n",
    "    preds = model.predict(\"\"\"TODO: Fill in the appropriate code\"\"\")[0]\n",
    "    pred_label = CLASSES[\"\"\"TODO: Fill in the appropriate code\"\"\"]\n",
    "    print(f\"Predicted label: {pred_label}\")\n",
    "\n",
    "    return perturbed_image, delta_tensor"
   ],
   "metadata": {
    "id": "DCup9sLXcI5y"
   },
   "id": "DCup9sLXcI5y",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "id": "684996b3d1438f65"
   },
   "cell_type": "markdown",
   "source": [
    "## 5. Running the Attack\n",
    "\n",
    "Now we can run our attack and visualize the results:"
   ],
   "id": "684996b3d1438f65"
  },
  {
   "metadata": {
    "id": "79173a858b452e31",
    "outputId": "f3d83911-56d9-4e14-e89f-60dba8334ed4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "cell_type": "code",
   "source": [
    "# Select a sample image\n",
    "index = 15  # Example index\n",
    "sample_val_image = np.expand_dims(batch_images[index], 0)\n",
    "\n",
    "# Run attack on standard EfficientNet\n",
    "print(\"Attack on Standard EfficientNet:\")\n",
    "perturbed_standard, delta_standard = perturb_image(\n",
    "    model_eb0,\n",
    "    sample_val_image,\n",
    "    batch_labels[index].numpy(),\n",
    "    4  # Target class (tulips)\n",
    ")\n",
    "\n",
    "# Run attack on AdvProp EfficientNet\n",
    "print(\"\\nAttack on AdvProp EfficientNet:\")\n",
    "\n",
    "# TODO: Fill in the appropriate code\n",
    "perturbed_advprop, delta_advprop = \"\"\"TODO: Fill in the appropriate code\"\"\"\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(sample_val_image[0].astype(\"uint8\"))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(perturbed_standard[0].numpy().astype(\"uint8\"))\n",
    "plt.title(\"Standard EfficientNet Attack\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(perturbed_advprop[0].numpy().astype(\"uint8\"))\n",
    "plt.title(\"AdvProp EfficientNet Attack\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "id": "79173a858b452e31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "5dddde9dc6cbc26c"
   },
   "cell_type": "markdown",
   "source": [],
   "id": "5dddde9dc6cbc26c"
  },
  {
   "metadata": {
    "id": "ec17bf4d1ce9d284"
   },
   "cell_type": "markdown",
   "source": [
    "## 6. Analysis and Discussion\n",
    "\n",
    "### Key Observations\n",
    "1. The adversarial perturbations are imperceptible to human eyes but can fool the model\n",
    "2. AdvProp training provides some robustness against adversarial attacks\n",
    "3. The attack success rate varies between the two models\n",
    "\n",
    "### Security Implications\n",
    "- Model vulnerabilities in real-world applications\n",
    "- Importance of adversarial training\n",
    "- Trade-offs between accuracy and robustness\n",
    "\n",
    "## Additional Resources\n",
    "1. [AdvProp Paper](https://arxiv.org/abs/1911.09665)\n",
    "2. [EfficientNet Paper](https://arxiv.org/abs/1905.11946)\n",
    "3. [PGD Attack Paper](https://arxiv.org/abs/1706.06083)\n",
    "\n",
    "## Exercises for Participants\n",
    "1. Try different epsilon values for the attack\n",
    "2. Experiment with different target classes\n",
    "3. Modify the attack algorithm parameters\n",
    "4. Compare results with different model architectures"
   ],
   "id": "ec17bf4d1ce9d284"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "machine_shape": "hm",
   "gpuType": "V28",
   "include_colab_link": true
  },
  "accelerator": "TPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
