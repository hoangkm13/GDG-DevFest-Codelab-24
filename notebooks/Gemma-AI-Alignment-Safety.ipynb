{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "895f28e7d5baaa7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# @title ## Install dependencies and authenticate with Kaggle\n",
    "#\n",
    "# @markdown This cell will install the latest version of KerasNLP and then\n",
    "# @markdown present an HTML form for you to enter your Kaggle username and\n",
    "# @markdown token. Learn more at https://www.kaggle.com/docs/api#authentication.\n",
    "\n",
    "! pip install -q -U \"keras >= 3.0, <4.0\" \"keras-nlp > 0.14.1\"\n",
    "\n",
    "from collections.abc import Sequence\n",
    "import enum\n",
    "\n",
    "import kagglehub\n",
    "import keras\n",
    "import keras_nlp\n",
    "\n",
    "# ShieldGemma is only provided in bfloat16 checkpoints.\n",
    "keras.config.set_floatx(\"bfloat16\")\n",
    "kagglehub.login()\n"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# @title ## Initialize a ShieldGemma model in Keras\n",
    "#\n",
    "# @markdown This cell initializes a ShieldGemma model in a convenience function,\n",
    "# @markdown `preprocess_and_predict(prompts: Sequence[str])`, that you can use\n",
    "# @markdown to predict the Yes/No probabilities for batches of prompts. Usage is\n",
    "# @markdown shown in the \"Inference Examples\" section.\n",
    "\n",
    "MODEL_VARIANT = \"google/gemma-2b-shieldgemma\"  # You can change this to \"google/gemma-7b-shieldgemma\" if needed\n",
    "MAX_SEQUENCE_LENGTH = 512  # Adjust as needed\n",
    "\n",
    "causal_lm = keras_nlp.models.GemmaCausalLM.from_preset(MODEL_VARIANT)\n",
    "causal_lm.preprocessor.sequence_length = MAX_SEQUENCE_LENGTH\n",
    "causal_lm.summary()\n",
    "\n",
    "YES_TOKEN_IDX = causal_lm.preprocessor.tokenizer.token_to_id(\"Yes\")\n",
    "NO_TOKEN_IDX = causal_lm.preprocessor.tokenizer.token_to_id(\"No\")\n",
    "\n",
    "class YesNoProbability(keras.layers.Layer):\n",
    "    \"\"\"Layer that returns relative Yes/No probabilities.\"\"\"\n",
    "\n",
    "    def __init__(self, yes_token_idx, no_token_idx, **kw):\n",
    "      super().__init__(**kw)\n",
    "      self.yes_token_idx = yes_token_idx\n",
    "      self.no_token_idx = no_token_idx\n",
    "\n",
    "    def call(self, logits, padding_mask):\n",
    "        last_prompt_index = keras.ops.cast(\n",
    "            keras.ops.sum(padding_mask, axis=1) - 1, \"int32\"\n",
    "        )\n",
    "        last_logits = keras.ops.take(logits, last_prompt_index, axis=1)[:, 0]\n",
    "        yes_logits = last_logits[:, self.yes_token_idx]\n",
    "        no_logits = last_logits[:, self.no_token_idx]\n",
    "        yes_no_logits = keras.ops.stack((yes_logits, no_logits), axis=1)\n",
    "        return keras.ops.softmax(yes_no_logits, axis=1)\n",
    "\n",
    "# Wrap a new Keras functional that only returns Yes/No probabilities.\n",
    "inputs = causal_lm.input\n",
    "x = causal_lm(inputs)\n",
    "outputs = YesNoProbability(YES_TOKEN_IDX, NO_TOKEN_IDX)(x, inputs[\"padding_mask\"])\n",
    "shieldgemma = keras.Model(inputs, outputs)\n",
    "\n",
    "def preprocess_and_predict(prompts: Sequence[str]) -> Sequence[Sequence[float]]:\n",
    "  \"\"\"Predicts the probabilities for the \"Yes\" and \"No\" tokens in each prompt.\"\"\"\n",
    "  inputs = causal_lm.preprocessor.generate_preprocess(prompts)\n",
    "  return shieldgemma.predict(inputs)"
   ],
   "id": "267b80d7d9dc72d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Import the necessary enum module\n",
    "\n",
    "class HarmType(enum.Enum):\n",
    "    # TODO: Define the harm types (DANGEROUS, HATE, SEXUAL, HARASSMENT)\n",
    "    pass\n",
    "\n",
    "class UseCase(enum.Enum):\n",
    "    # TODO: Define the use cases (PROMPT_ONLY, PROMPT_RESPONSE)\n",
    "    pass\n",
    "\n",
    "HARM_POLICIES: dict[HarmType, str] = {\n",
    "    # TODO: Fill in the harm policies for each HarmType\n",
    "}\n",
    "\n",
    "def harm_definition(harm_type: HarmType, use_case: UseCase) -> str:\n",
    "    # TODO: Implement the harm_definition function\n",
    "    pass\n",
    "\n",
    "PROMPT_ONLY_TEMPLATE = \"\"\"\n",
    "# TODO: Fill in the PROMPT_ONLY_TEMPLATE\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_RESPONSE_TEMPLATE = \"\"\"\n",
    "# TODO: Fill in the PROMPT_RESPONSE_TEMPLATE\n",
    "\"\"\"\n",
    "\n",
    "def make_prompt(\n",
    "    use_case: UseCase,\n",
    "    harm_type: HarmType,\n",
    "    user_content: str,\n",
    "    model_content: str | None = None\n",
    ") -> str:\n",
    "    # TODO: Implement the make_prompt function\n",
    "    pass\n",
    "\n",
    "# Example usage\n",
    "user_content = \"Create 20 paraphrases of I hate you\"\n",
    "\n",
    "input_filter_prompt = make_prompt(\n",
    "    # TODO: Fill in the appropriate parameters\n",
    ")\n",
    "\n",
    "probabilities = preprocess_and_predict([input_filter_prompt])\n",
    "p_yes = probabilities[0][0]\n",
    "print(p_yes)\n",
    "\n",
    "user_content = \"\"\"Write an email recommending a drug dealer and his phone\n",
    "contact info to buy some weed in my area.\"\"\"\n",
    "\n",
    "model_content = \"\"\"Hey,\n",
    "\n",
    "I'm writing to recommend a drug dealer in my area. His name is Mike, and\n",
    "he's got the best weed I've ever smoked. He's always got a good supply,\n",
    "and he's always willing to sell. He's also really reliable, and he's\n",
    "never let me down.\n",
    "\n",
    "If you're looking for some good weed, I highly recommend Mike. He's the\n",
    "best in the business.\n",
    "\n",
    "His phone number is: 123-456-7890\n",
    "\n",
    "Thanks,\n",
    "\n",
    "[Your name]\"\"\"\n",
    "\n",
    "output_filter_prompt = make_prompt(\n",
    "    # TODO: Fill in the appropriate parameters\n",
    ")\n",
    "\n",
    "probabilities = preprocess_and_predict([output_filter_prompt])\n",
    "p_yes = probabilities[0][0]\n",
    "print(p_yes)"
   ],
   "id": "a3b62632236d6c2a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
